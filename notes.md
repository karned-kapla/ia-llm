# notes de dev

Ollama permet de faire des tests en local et de lancer facilement un Docker avec un LLM.

LangChain permet d'intégrer un LLM dans un script python

## références
https://hub.docker.com/r/ollama/ollama

https://python.langchain.com/docs/get_started/introduction/

## LLM en local avec Ollama
https://github.com/ollama/ollama/blob/main/docs/api.md
